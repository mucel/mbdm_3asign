{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad96fa1",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b18233d",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "392605b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "    # Copied from exmaple notebook \n",
    "    \n",
    "from mesa import Agent, Model\n",
    "from mesa.time import SimultaneousActivation\n",
    "from mesa.space import NetworkGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import annotations\n",
    "from typing import Tuple, List, Iterable, Dict, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed \n",
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca5928",
   "metadata": {},
   "source": [
    "# Baseline Analysis\n",
    "Run a baseline system analysis for the EV Stag Hunt model:\n",
    "- Heatmap of final adoption X* vs (X0, I0)\n",
    "- Phase plots (I(t), X(t)) for representative initial conditions\n",
    "- Sensitivity curves: final adoption vs beta_I for several X0\n",
    "\n",
    "Produces PNG plots and CSV data in ./output_ev_analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431be870",
   "metadata": {},
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bd34bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy update functions\n",
    "\n",
    "def choose_strategy_imitate(agent, neighbors):\n",
    "    \"\"\"Choose strategy of the highest-payoff neighbour (including self).\"\"\"\n",
    "    candidates = neighbors + [agent]\n",
    "    best = max(candidates, key=lambda a: a.payoff)\n",
    "    return best.strategy\n",
    "\n",
    "\n",
    "def choose_strategy_logit(agent, neighbors, a_I, b, tau):\n",
    "    \"\"\"Choose strategy using logit / softmax choice.\n",
    "\n",
    "    Parameters\n",
    "    - agent: the agent choosing a strategy\n",
    "    - neighbors: list of neighbour agents\n",
    "    - a_I: effective coordination payoff given current infrastructure\n",
    "    - b: defection payoff\n",
    "    - tau: temperature parameter for softmax\n",
    "    \"\"\"\n",
    "    # compute expected payoffs for C and D\n",
    "    pi_C = 0.0\n",
    "    pi_D = 0.0\n",
    "    for other in neighbors:\n",
    "        s_j = other.strategy\n",
    "        if s_j == \"C\":\n",
    "            pi_C += a_I\n",
    "            pi_D += b\n",
    "        else:\n",
    "            pi_C += 0.0\n",
    "            pi_D += b\n",
    "\n",
    "    # softmax choice\n",
    "    denom = np.exp(pi_C / tau) + np.exp(pi_D / tau)\n",
    "    P_C = np.exp(pi_C / tau) / denom if denom > 0 else 0.5\n",
    "    return \"C\" if random.random() < P_C else \"D\"\n",
    "\n",
    "# Agent and Model classes\n",
    "\n",
    "class EVAgent:\n",
    "    def __init__(self, node_id: int, model: \"EVStagHuntModel\", init_strategy: str = \"D\"):\n",
    "        self.node_id = node_id\n",
    "        self.model = model\n",
    "        self.strategy = init_strategy  # \"C\" or \"D\"\n",
    "        self.payoff = 0.0\n",
    "        self.next_strategy = init_strategy\n",
    "\n",
    "    def step(self) -> None:\n",
    "        \"\"\"Compute payoff from interactions with neighbours.\"\"\"\n",
    "        I = self.model.infrastructure\n",
    "        a0 = self.model.a0\n",
    "        beta_I = self.model.beta_I\n",
    "        b = self.model.b\n",
    "        a_I = a0 + beta_I * I\n",
    "\n",
    "        neighbors = list(self.model.G.neighbors(self.node_id))\n",
    "        if not neighbors:\n",
    "            self.payoff = 0.0\n",
    "            return\n",
    "\n",
    "        payoff = 0.0\n",
    "        for nbr in neighbors:\n",
    "            other = self.model.node_agent_map[nbr]\n",
    "            s_i = self.strategy\n",
    "            s_j = other.strategy\n",
    "            if s_i == \"C\" and s_j == \"C\":\n",
    "                payoff += a_I\n",
    "            elif s_i == \"C\" and s_j == \"D\":\n",
    "                payoff += 0.0\n",
    "            elif s_i == \"D\" and s_j == \"C\":\n",
    "                payoff += b\n",
    "            else:  # D vs D\n",
    "                payoff += b\n",
    "        self.payoff = payoff\n",
    "\n",
    "    def advance(self) -> None:\n",
    "        \"\"\"Compute next_strategy according to model's strategy_choice_func but DO NOT commit.\"\"\"\n",
    "        func = self.model.strategy_choice_func\n",
    "        neighbors = [self.model.node_agent_map[n] for n in self.model.G.neighbors(self.node_id)]\n",
    "\n",
    "        if func == \"imitate\":\n",
    "            candidates = neighbors + [self]\n",
    "            best = max(candidates, key=lambda a: a.payoff)\n",
    "            self.next_strategy = best.strategy\n",
    "        elif func == \"logit\":\n",
    "            a_I = self.model.a0 + self.model.beta_I * self.model.infrastructure\n",
    "            pi_C = 0.0\n",
    "            pi_D = 0.0\n",
    "            for other in neighbors:\n",
    "                if other.strategy == \"C\":\n",
    "                    pi_C += a_I\n",
    "                    pi_D += self.model.b\n",
    "                else:\n",
    "                    pi_C += 0.0\n",
    "                    pi_D += self.model.b\n",
    "            tau = getattr(self.model, \"tau\", 1.0)\n",
    "            denom = math.exp(pi_C / tau) + math.exp(pi_D / tau)\n",
    "            P_C = math.exp(pi_C / tau) / denom if denom > 0 else 0.5\n",
    "            self.next_strategy = \"C\" if random.random() < P_C else \"D\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown strategy choice function: {func}\")\n",
    "\n",
    "    def commit(self) -> None:\n",
    "        \"\"\"Apply next_strategy synchronously.\"\"\"\n",
    "        self.strategy = self.next_strategy\n",
    "\n",
    "\n",
    "class EVStagHuntModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        initial_ev: int,\n",
    "        a0: float,\n",
    "        beta_I: float,\n",
    "        b: float,\n",
    "        g_I: float,\n",
    "        I0: float,\n",
    "        seed: int | None,\n",
    "        network_type: str,\n",
    "        n_nodes: int,\n",
    "        p: float,\n",
    "        m: int,\n",
    "        strategy_choice_func: str = \"imitate\",\n",
    "        tau: float = 1.0,\n",
    "    ):\n",
    "        self.random = random.Random(seed)\n",
    "        self.seed = seed\n",
    "        self.a0 = a0\n",
    "        self.beta_I = beta_I\n",
    "        self.b = b\n",
    "        self.g_I = g_I\n",
    "        self.infrastructure = float(I0)\n",
    "        self.strategy_choice_func = strategy_choice_func\n",
    "        self.tau = tau\n",
    "\n",
    "        # Build network\n",
    "        if network_type == \"ER\":\n",
    "            G = nx.erdos_renyi_graph(n_nodes, p, seed=seed)\n",
    "        elif network_type == \"WS\":\n",
    "            G = nx.watts_strogatz_graph(n_nodes, max(2, m), p, seed=seed)\n",
    "        elif network_type == \"BA\":\n",
    "            G = nx.barabasi_albert_graph(n_nodes, max(1, m), seed=seed)\n",
    "\n",
    "        # if graph disconnected, keep largest connected component (avoids isolated nodes effects)\n",
    "        if not nx.is_connected(G) and len(G) > 0:\n",
    "            comp = max(nx.connected_components(G), key=len)\n",
    "            G = G.subgraph(comp).copy()\n",
    "        self.G = G\n",
    "\n",
    "        # create agents: one per node\n",
    "        nodes = list(self.G.nodes())\n",
    "        total_nodes = len(nodes)\n",
    "        k_ev = max(0, min(initial_ev, total_nodes))\n",
    "        ev_nodes = set(self.random.sample(nodes, k_ev))\n",
    "        self.node_agent_map: Dict[int, EVAgent] = {}\n",
    "        for node in nodes:\n",
    "            init_strategy = \"C\" if node in ev_nodes else \"D\"\n",
    "            agent = EVAgent(node, self, init_strategy)\n",
    "            self.node_agent_map[node] = agent\n",
    "\n",
    "    def get_adoption_fraction(self) -> float:\n",
    "        agents = list(self.node_agent_map.values())\n",
    "        if not agents:\n",
    "            return 0.0\n",
    "        return sum(1 for a in agents if a.strategy == \"C\") / len(agents)\n",
    "\n",
    "    def step(self) -> None:\n",
    "        # compute payoffs\n",
    "        for agent in list(self.node_agent_map.values()):\n",
    "            agent.step()\n",
    "        # choose next strategies (based on payoffs)\n",
    "        for agent in list(self.node_agent_map.values()):\n",
    "            agent.advance()\n",
    "        # commit synchronously\n",
    "        for agent in list(self.node_agent_map.values()):\n",
    "            agent.commit()\n",
    "        # update infrastructure: I <- clip(I + g_I*(X - I), 0, 1)\n",
    "        X = self.get_adoption_fraction()\n",
    "        I = self.infrastructure\n",
    "        dI = self.g_I * (X - I)\n",
    "        self.infrastructure = float(min(1.0, max(0.0, I + dI)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ba6f2",
   "metadata": {},
   "source": [
    "### Runner Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f519b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(\n",
    "    X0_frac: float,\n",
    "    I0: float,\n",
    "    *,\n",
    "    a0: float,\n",
    "    beta_I: float,\n",
    "    b: float,\n",
    "    g_I: float,\n",
    "    T: int,\n",
    "    network_type: str,\n",
    "    n_nodes: int,\n",
    "    p: float,\n",
    "    m: int,\n",
    "    seed: Optional[int],\n",
    "    strategy_choice_func: str,\n",
    "    tau: float = 1.0,\n",
    "    record_trajectory: bool = False,\n",
    ") -> Tuple[float, Tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"Run a single trial. Returns final adoption and optional trajectories (X(t), I(t)).\"\"\"\n",
    "    initial_ev = int(round(X0_frac * n_nodes))\n",
    "    model = EVStagHuntModel(\n",
    "        initial_ev=initial_ev,\n",
    "        a0=a0,\n",
    "        beta_I=beta_I,\n",
    "        b=b,\n",
    "        g_I=g_I,\n",
    "        I0=I0,\n",
    "        seed=seed,\n",
    "        network_type=network_type,\n",
    "        n_nodes=n_nodes,\n",
    "        p=p,\n",
    "        m=m,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "    )\n",
    "    X_traj = []\n",
    "    I_traj = []\n",
    "    for t in range(T):\n",
    "        if record_trajectory:\n",
    "            X_traj.append(model.get_adoption_fraction())\n",
    "            I_traj.append(model.infrastructure)\n",
    "        model.step()\n",
    "    if record_trajectory:\n",
    "        X_traj.append(model.get_adoption_fraction())\n",
    "        I_traj.append(model.infrastructure)\n",
    "    final = model.get_adoption_fraction()\n",
    "    return final, (np.array(X_traj), np.array(I_traj))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b956761f",
   "metadata": {},
   "source": [
    "### Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fd09190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_final_adoption(\n",
    "    X0_grid: Iterable[float],\n",
    "    I0_grid: Iterable[float],\n",
    "    *,\n",
    "    a0: float,\n",
    "    beta_I: float,\n",
    "    b: float,\n",
    "    g_I: float,\n",
    "    n_nodes: int,\n",
    "    p: float,\n",
    "    m: int,\n",
    "    T: int,\n",
    "    trials_per_cell: int,\n",
    "    network_type: str,\n",
    "    strategy_choice_func: str,\n",
    "    tau: float,\n",
    "    seed_base: int,\n",
    "    out_dir: str,\n",
    ") -> Tuple[List[float], List[float], np.ndarray]:\n",
    "    \"\"\"Compute mean final adoption X* for every (X0, I0) cell and save CSV.\"\"\"\n",
    "    X0_vals = list(X0_grid)\n",
    "    I0_vals = list(I0_grid)\n",
    "    H = np.zeros((len(I0_vals), len(X0_vals)), dtype=float)  # rows: I0, cols: X0\n",
    "    meta = {}\n",
    "    for i, I0 in enumerate(I0_vals):\n",
    "        for j, X0 in enumerate(X0_vals):\n",
    "            finals = []\n",
    "            for k in range(trials_per_cell):\n",
    "                seed = seed_base + i * 10000 + j * 100 + k\n",
    "                final, _ = run_trial(\n",
    "                    X0_frac=X0,\n",
    "                    I0=I0,\n",
    "                    a0=a0,\n",
    "                    beta_I=beta_I,\n",
    "                    b=b,\n",
    "                    g_I=g_I,\n",
    "                    T=T,\n",
    "                    network_type=network_type,\n",
    "                    n_nodes=n_nodes,\n",
    "                    p=p,\n",
    "                    m=m,\n",
    "                    seed=seed,\n",
    "                    strategy_choice_func=strategy_choice_func,\n",
    "                    tau=tau,\n",
    "                    record_trajectory=False,\n",
    "                )\n",
    "                finals.append(final)\n",
    "            H[i, j] = float(np.mean(finals))\n",
    "            meta[(I0, X0)] = {\"finals\": finals, \"mean\": float(np.mean(finals)), \"std\": float(np.std(finals))}\n",
    "    # Save CSV\n",
    "    df = pd.DataFrame(H, index=[f\"I0={v:.3f}\" for v in I0_vals], columns=[f\"X0={v:.3f}\" for v in X0_vals])\n",
    "    df.to_csv(os.path.join(out_dir, \"heatmap_final_adoption.csv\"))\n",
    "    return X0_vals, I0_vals, H\n",
    "\n",
    "def sensitivity_betaI_with_trials(\n",
    "    beta_vals: Iterable[float],\n",
    "    X0_values: Iterable[float],\n",
    "    *,\n",
    "    I0: float,\n",
    "    a0: float,\n",
    "    b: float,\n",
    "    g_I: float,\n",
    "    n_nodes: int,\n",
    "    p: float,\n",
    "    m: int,\n",
    "    T: int,\n",
    "    trials: int,\n",
    "    network_type: str,\n",
    "    strategy_choice_func: str,\n",
    "    tau: float,\n",
    "    seed_base: int,\n",
    "    out_dir: str,\n",
    ") -> Tuple[List[float], List[float], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute final adoption vs beta_I for each initial X0 in X0_values.\n",
    "    Returns all trial results (shape: [X0, beta_I, trial]) for mean Â± std plotting.\n",
    "    \"\"\"\n",
    "    beta_vals = list(beta_vals)\n",
    "    X0_values = list(X0_values)\n",
    "    all_trials = np.zeros((len(X0_values), len(beta_vals), trials), dtype=float)\n",
    "\n",
    "    for i, X0 in enumerate(X0_values):\n",
    "        for j, beta in enumerate(beta_vals):\n",
    "            for k in range(trials):\n",
    "                seed = seed_base + i * 10000 + j * 100 + k\n",
    "                final, _ = run_trial(\n",
    "                    X0_frac=X0,\n",
    "                    I0=I0,\n",
    "                    a0=a0,\n",
    "                    beta_I=beta,\n",
    "                    b=b,\n",
    "                    g_I=g_I,\n",
    "                    T=T,\n",
    "                    network_type=network_type,\n",
    "                    n_nodes=n_nodes,\n",
    "                    p=p,\n",
    "                    m=m,\n",
    "                    seed=seed,\n",
    "                    strategy_choice_func=strategy_choice_func,\n",
    "                    tau=tau,\n",
    "                    record_trajectory=False,\n",
    "                )\n",
    "                all_trials[i, j, k] = final\n",
    "\n",
    "    # Optional: save mean results to CSV\n",
    "    means = all_trials.mean(axis=2)\n",
    "    df = pd.DataFrame(means, index=[f\"X0={v:.3f}\" for v in X0_values],\n",
    "                      columns=[f\"beta_I={v:.3f}\" for v in beta_vals])\n",
    "    df.to_csv(os.path.join(out_dir, \"sensitivity_betaI_mean.csv\"))\n",
    "\n",
    "    return X0_values, beta_vals, all_trials    \n",
    "\n",
    "def collect_trajectories(\n",
    "    cases: List[Tuple[float, float]],\n",
    "    *,\n",
    "    a0: float,\n",
    "    beta_I: float,\n",
    "    b: float,\n",
    "    g_I: float,\n",
    "    n_nodes: int,\n",
    "    p: float,\n",
    "    m: int,\n",
    "    T: int,\n",
    "    network_type: str,\n",
    "    strategy_choice_func: str,\n",
    "    tau: float,\n",
    "    seed_base: int,\n",
    "    out_dir: str,\n",
    ") -> Dict[Tuple[float, float], Dict]:\n",
    "    \"\"\"Run representative trajectories and return time-series, without plotting.\"\"\"\n",
    "    trajs = {}\n",
    "    for idx, (X0, I0) in enumerate(cases):\n",
    "        seed = seed_base + idx * 100\n",
    "        final, (X_traj, I_traj) = run_trial(\n",
    "            X0_frac=X0,\n",
    "            I0=I0,\n",
    "            a0=a0,\n",
    "            beta_I=beta_I,\n",
    "            b=b,\n",
    "            g_I=g_I,\n",
    "            T=T,\n",
    "            network_type=network_type,\n",
    "            n_nodes=n_nodes,\n",
    "            p=p,\n",
    "            m=m,\n",
    "            seed=seed,\n",
    "            strategy_choice_func=strategy_choice_func,\n",
    "            tau=tau,\n",
    "            record_trajectory=True,\n",
    "        )\n",
    "        trajs[(X0, I0)] = {\"final\": final, \"X\": X_traj, \"I\": I_traj}\n",
    "\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b427a270",
   "metadata": {},
   "source": [
    "### Configure and Run Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "60ef9abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#  HEATMAP ANALYSIS\n",
    "# ============================================================\n",
    "def run_heatmap_analysis(\n",
    "    out_dir,\n",
    "    X0_grid,\n",
    "    I0_grid,\n",
    "    a0,\n",
    "    beta_I,\n",
    "    b,\n",
    "    g_I,\n",
    "    n_nodes,\n",
    "    p,\n",
    "    m,\n",
    "    T,\n",
    "    trials_per_cell,\n",
    "    network_type,\n",
    "    strategy_choice_func,\n",
    "    tau,\n",
    "    seed_base,\n",
    "):\n",
    "    print(\"Starting heatmap sweep (this may take some time)...\")\n",
    "\n",
    "    X0_vals, I0_vals, H = heatmap_final_adoption(\n",
    "        X0_grid=X0_grid,\n",
    "        I0_grid=I0_grid,\n",
    "        a0=a0,\n",
    "        beta_I=beta_I,\n",
    "        b=b,\n",
    "        g_I=g_I,\n",
    "        n_nodes=n_nodes,\n",
    "        p=p,\n",
    "        m=m,\n",
    "        T=T,\n",
    "        trials_per_cell=trials_per_cell,\n",
    "        network_type=network_type,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "        seed_base=seed_base,\n",
    "        out_dir=out_dir,\n",
    "    )\n",
    "\n",
    "    # Save heatmap figure\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    im = plt.imshow(\n",
    "        H,\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "        extent=[X0_vals[0], X0_vals[-1], I0_vals[0], I0_vals[-1]],\n",
    "    )\n",
    "    plt.colorbar(im, label=r'Mean final adoption $X^*$')\n",
    "    plt.xlabel(r'Initial adoption $X_0$')\n",
    "    plt.ylabel(r'Initial infrastructure $I_0$')\n",
    "    plt.title(fr'Heatmap: Mean final adoption $X^*$ vs ($X_0$, $I_0$) ($\\beta_I$={beta_I:.2f})')\n",
    "    plt.tight_layout()\n",
    "    fname = os.path.join(out_dir, \"heatmap_final_adoption.png\")\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Heatmap saved to:\", fname)\n",
    "\n",
    "    return X0_vals, I0_vals, H\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  SENSITIVITY ANALYSIS\n",
    "# ============================================================\n",
    "def run_sensitivity_analysis(\n",
    "    out_dir,\n",
    "    beta_vals,\n",
    "    X0_sens,\n",
    "    I0,\n",
    "    a0,\n",
    "    b,\n",
    "    g_I,\n",
    "    n_nodes,\n",
    "    p,\n",
    "    m,\n",
    "    T,\n",
    "    trials,\n",
    "    network_type,\n",
    "    strategy_choice_func,\n",
    "    tau,\n",
    "    seed_base,\n",
    "):\n",
    "    print(\"Starting sensitivity sweep over beta_I ...\")\n",
    "\n",
    "    X0_list, betas, sens_res = sensitivity_betaI_with_trials(\n",
    "        beta_vals=beta_vals,\n",
    "        X0_values=X0_sens,\n",
    "        I0=I0,\n",
    "        a0=a0,\n",
    "        b=b,\n",
    "        g_I=g_I,\n",
    "        n_nodes=n_nodes,\n",
    "        p=p,\n",
    "        m=m,\n",
    "        T=T,\n",
    "        trials=trials,\n",
    "        network_type=network_type,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "        seed_base=seed_base,\n",
    "        out_dir=out_dir,\n",
    "    )\n",
    "\n",
    "    # Compute mean across trials\n",
    "    mean_vals = np.mean(sens_res, axis=2)\n",
    "\n",
    "    # Plot only the mean\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    for i, x0 in enumerate(X0_list):\n",
    "        plt.plot(betas, mean_vals[i, :], label=f\"X0={x0:.2f}\", marker=\"o\", linewidth=1)\n",
    "\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.xlabel(r'$\\beta_I$')\n",
    "    plt.ylabel(r'Mean Final Adoption $X^*$')\n",
    "    plt.title(r'Sensitivity: Final Adoption vs $\\beta_I$')\n",
    "    plt.legend(title=r\"Initial Adoption $X_0$\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fname = os.path.join(out_dir, \"sensitivity_betaI_mean_only.png\")\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "    print(\"Sensitivity plot saved to:\", fname)\n",
    "\n",
    "    return X0_list, betas, mean_vals\n",
    "\n",
    "# ============================================================\n",
    "#  PHASE TRAJECTORY PLOTS\n",
    "# ============================================================\n",
    "def run_phase_plots(\n",
    "    out_dir,\n",
    "    phase_cases,\n",
    "    a0,\n",
    "    beta_I,\n",
    "    b,\n",
    "    g_I,\n",
    "    n_nodes,\n",
    "    p,\n",
    "    m,\n",
    "    T,\n",
    "    network_type,\n",
    "    strategy_choice_func,\n",
    "    tau,\n",
    "    seed_base,\n",
    "):\n",
    "    print(\"Collecting representative trajectories...\")\n",
    "\n",
    "    trajs = collect_trajectories(\n",
    "        phase_cases,\n",
    "        a0=a0,\n",
    "        beta_I=beta_I,\n",
    "        b=b,\n",
    "        g_I=g_I,\n",
    "        n_nodes=n_nodes,\n",
    "        p=p,\n",
    "        m=m,\n",
    "        T=T,\n",
    "        network_type=network_type,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "        seed_base=seed_base,\n",
    "        out_dir=out_dir,\n",
    "    )\n",
    "\n",
    "    print(\"Creating combined phase plot...\")\n",
    "\n",
    "    # -------------------------\n",
    "    #  Combined Phase Plot\n",
    "    # -------------------------\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    for (I0, X0), data in trajs.items():\n",
    "        plt.plot(\n",
    "            data[\"X\"],\n",
    "            data[\"I\"],\n",
    "            label=f\"X0={X0:.2f}, I0={I0:.2f}\",\n",
    "            linewidth=1.5\n",
    "            # attribute a color scheme of green to the lines\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Adoption X(t)\")\n",
    "    plt.ylabel(\"Infrastructure I(t)\")\n",
    "    plt.title(\"Phase Plot (I (t), X (t))\")\n",
    "    plt.legend(loc=\"upper left\", fontsize=6)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fname_phase = os.path.join(out_dir, \"ER_phase.png\")\n",
    "    plt.savefig(fname_phase)\n",
    "    plt.close()\n",
    "\n",
    "    # -------------------------\n",
    "    #  Combined Time Series Plot\n",
    "    # -------------------------\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    for (X0, I0), data in trajs.items():\n",
    "        t = np.arange(len(data[\"X\"]))\n",
    "        plt.plot(t, data[\"X\"], label=f\"X(t)  X0={X0:.2f}, I0={I0:.2f}\", linewidth=1)\n",
    "        plt.plot(t, data[\"I\"], linestyle=\"--\", label=f\"I(t)  X0={X0:.2f}, I0={I0:.2f}\")\n",
    "\n",
    "    plt.xlabel(\"time step\")\n",
    "    plt.ylabel(\"value\")\n",
    "    plt.title(\"Combined Time Series for All Phase Cases\")\n",
    "    plt.legend(ncol=2, fontsize=8, loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #add a grid to the figure\n",
    "    plt.grid()\n",
    "\n",
    "    fname_time = os.path.join(out_dir, \"timeseries_phase_cases.png\")\n",
    "    plt.savefig(fname_time)\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Combined phase and time-series plots saved to:\", out_dir)\n",
    "\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "75ab11db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sensitivity sweep over beta_I ...\n",
      "Sensitivity plot saved to: output_ev_analysis/sensitivity_betaI_mean_only.png\n",
      "All done. Artifacts written to: output_ev_analysis\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "#  MAIN ORCHESTRATOR\n",
    "# ============================================================\n",
    "def main():\n",
    "    out_dir = \"output_ev_analysis\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # ---- Config: adjust these for more/less compute ----\n",
    "    a0 = 2.0\n",
    "    b = 1.0\n",
    "    g_I = 0.05\n",
    "\n",
    "    network_type = \"ER\"  # \"ER\", \"WS\", or \"BA\"\n",
    "    n_nodes = 200\n",
    "    p = 0.05\n",
    "    m = 2\n",
    "\n",
    "    strategy_choice_func = \"imitate\"\n",
    "    tau = 1.0\n",
    "    T = 500\n",
    "\n",
    "    X0_grid = np.linspace(0.0, 1.0, 20)\n",
    "    I0_grid = np.linspace(0.0, 1.0, 20)\n",
    "    trials_per_cell = 8\n",
    "\n",
    "    beta_vals = np.linspace(0.0, 4.0, 20)\n",
    "    X0_sens = [0.2, 0.3, 0.4, 0.5]\n",
    "    sensitivity_trials = 8\n",
    "\n",
    "    phase_cases = [\n",
    "        (0.2, 0.2),\n",
    "        (0.2, 0.5),\n",
    "        (0.2, 0.8),\n",
    "        (0.4, 0.2),\n",
    "        (0.4, 0.5),\n",
    "        (0.4, 0.8),\n",
    "    ]\n",
    "\n",
    "    seed_base_heatmap = 42\n",
    "    seed_base_sensitivity = 42\n",
    "    seed_base_phase = 42\n",
    "\n",
    "    beta_I_baseline = 2.0\n",
    "    \n",
    "    # X0_vals, I0_vals, H = run_heatmap_analysis(\n",
    "    #     out_dir, X0_grid, I0_grid, a0, beta_I_baseline, b, g_I,\n",
    "    #     n_nodes, p, m, T, trials_per_cell,\n",
    "    #     network_type, strategy_choice_func, tau,\n",
    "    #     seed_base_heatmap\n",
    "    # )\n",
    "\n",
    "    X0_list, betas, mean_vals = run_sensitivity_analysis(\n",
    "        out_dir, beta_vals, X0_sens, 0.05, a0, b, g_I,\n",
    "        n_nodes, p, m, T, sensitivity_trials,\n",
    "        network_type, strategy_choice_func, tau,\n",
    "        seed_base_sensitivity\n",
    "     )\n",
    "    \n",
    "    # trajs = run_phase_plots(\n",
    "    #      out_dir, phase_cases, a0, beta_I_baseline, b, g_I,\n",
    "    #      n_nodes, p, m, T,\n",
    "    #      network_type, strategy_choice_func, tau,\n",
    "    #      seed_base_phase\n",
    "    # )\n",
    "\n",
    "    # ---- Tipping estimate (rough) ----\n",
    "    #   threshold = 0.9\n",
    "    #   tipping_estimates = []\n",
    "    #   for i_idx, I0 in enumerate(I0_vals):\n",
    "    #       row = H[i_idx, :]\n",
    "    #       idxs = np.where(row >= threshold)[0]\n",
    "    #       tipping_estimates.append(\n",
    "    #           X0_vals[int(idxs[0])] if len(idxs) > 0 else np.nan\n",
    "    #       )\n",
    "\n",
    "    #   tipping_df = pd.DataFrame(\n",
    "    #       {\"I0\": I0_vals, \"min_X0_for_Xstar_ge_0.9\": tipping_estimates}\n",
    "    #   )\n",
    "    #   tipping_df.to_csv(os.path.join(out_dir, \"tipping_estimates.csv\"))\n",
    "\n",
    "    # ---- Artifact index ----\n",
    "    artifact_index = {\n",
    "        \"heatmap_png\": os.path.join(out_dir, \"heatmap_final_adoption.png\"),\n",
    "        \"sensitivity_png\": os.path.join(out_dir, \"sensitivity_betaI.png\"),\n",
    "        \"phase_plots_dir\": out_dir,\n",
    "        \"tipping_estimates_csv\": os.path.join(out_dir, \"tipping_estimates.csv\"),\n",
    "    }\n",
    "\n",
    "    pd.DataFrame(\n",
    "        list(artifact_index.items()),\n",
    "        columns=[\"artifact\", \"path\"]\n",
    "    ).to_csv(os.path.join(out_dir, \"artifact_index.csv\"), index=False)\n",
    "\n",
    "    print(\"All done. Artifacts written to:\", out_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a05368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
