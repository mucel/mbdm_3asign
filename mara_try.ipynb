{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6609752f",
   "metadata": {},
   "source": [
    "# Asignement 3 = Stag Hunt model \n",
    "By Māra Učelniece \n",
    "\n",
    "- Response : there is not a specific data set we have to use, but just apply the evaluation of the structures to the EV's case that we are attempting to create policy interventions for. \n",
    "\n",
    "## Questions : \n",
    "- Ask Noah : Do we want to find a data set ? \n",
    "\n",
    "### Task : \n",
    "Evaluate how varying structures relate to policy and in which cases they might apply. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "913ca26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Imports \n",
    "    # Copied from exmaple notebook \n",
    "    \n",
    "from mesa import Agent, Model\n",
    "from mesa.time import SimultaneousActivation\n",
    "from mesa.space import NetworkGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "from typing import Iterable, List, Dict\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "# Can import the functions from the course_matterial \n",
    "    # Example : from file import function\n",
    "from course_matterial.ev_core import *     \n",
    "    # Example to import all functions\n",
    "        # from ./course_matterial/ev_core.py import *\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10a620b",
   "metadata": {},
   "source": [
    "## 0. Implement a network agent based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a10dce85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empirical graph from 3_assignment_NM/data/bowdoin_network.csv: n=2250, m=84386\n"
     ]
    }
   ],
   "source": [
    "# Generate real-world network\n",
    "def build_real_network():\n",
    "    # Load CSV network\n",
    "    df = pd.read_csv('data/bowdoin_network.csv')\n",
    "    # Expect columns 'Source' and 'Target' as in the provided CSV\n",
    "    G = nx.from_pandas_edgelist(df, source='source', target='target', create_using=nx.Graph())\n",
    "    # Remove self-loops if present\n",
    "    G.remove_edges_from(list(nx.selfloop_edges(G)))\n",
    "    # Remove components that are not the biggest connected component\n",
    "    largest_cc = max(nx.connected_components(G), key=len)\n",
    "    G = G.subgraph(largest_cc).copy()\n",
    "    print(f\"Loaded empirical graph from 3_assignment_NM/data/bowdoin_network.csv: n={G.number_of_nodes()}, m={G.number_of_edges()}\")\n",
    "    return {'Bowdoin47': G}\n",
    "\n",
    "# Generate model networks Erdos-Renyi, Watts-Strogatz and Barabasi-Albert with the same number of nodes and average degree as the real-world network that we can call on later in the notebook to conduct baselines system analysis and network structure analysis. Assign these model networks to objects with the keys being the model names appended to the real-world network name.\n",
    "def generate_model_networks(real_graphs: Dict[str, nx.Graph]) -> Dict[str, nx.Graph]:\n",
    "    model_graphs = {}\n",
    "    for name, G in real_graphs.items():\n",
    "        n = G.number_of_nodes()\n",
    "        m = G.number_of_edges()\n",
    "        avg_degree = 2 * m / n\n",
    "\n",
    "        # Erdos-Renyi\n",
    "        p = avg_degree / (n - 1)\n",
    "        er_graph = nx.erdos_renyi_graph(n, p)\n",
    "        model_graphs[f\"{name}_ErdosRenyi\"] = er_graph\n",
    "\n",
    "        # Watts-Strogatz\n",
    "        k = int(avg_degree)\n",
    "        if k % 2 != 0:\n",
    "            k += 1  # Ensure k is even\n",
    "        ws_graph = nx.watts_strogatz_graph(n, k, 0.1)\n",
    "        model_graphs[f\"{name}_WattsStrogatz\"] = ws_graph\n",
    "\n",
    "        # Barabasi-Albert\n",
    "        m_ba = max(1, int(avg_degree / 2))\n",
    "        ba_graph = nx.barabasi_albert_graph(n, m_ba)\n",
    "        model_graphs[f\"{name}_BarabasiAlbert\"] = ba_graph\n",
    "\n",
    "    return model_graphs\n",
    "\n",
    "# Call the function to generate the real-world network\n",
    "graphs = build_real_network()\n",
    "{name: (G.number_of_nodes(), G.number_of_edges()) for name, G in graphs.items()}\n",
    "\n",
    "# Call the function to generate model networks\n",
    "model_graphs = generate_model_networks(graphs)\n",
    "all_graphs = {**graphs, **model_graphs}\n",
    "{name: (G.number_of_nodes(), G.number_of_edges()) for name, G in all_graphs.items()}\n",
    "\n",
    "bowdoin47_RW = graphs['Bowdoin47']\n",
    "bowdoin47_ER = model_graphs['Bowdoin47_ErdosRenyi']   \n",
    "bowdoin47_WS = model_graphs['Bowdoin47_WattsStrogatz']\n",
    "bowdoin47_BA = model_graphs['Bowdoin47_BarabasiAlbert']\n",
    "\n",
    "# Def advanced in ev_core =  applicable cuz then we can adjsut the strategy if want to evaluate the rule\n",
    "\n",
    "# But tghe class EVStagHuntModel(Model) also ... \n",
    "\n",
    "# Only till set_intial_adaptors the script seems usefull for now \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fac3eaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EVStagHuntModel' object has no attribute 'G'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the model with the pre-existing graph\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#  EVAgent(Agent) is in EVStagHuntModel(Model), so only need to call this \u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mEVStagHuntModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mG\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbowdoin47_RW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_ev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of initial EV nodes\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Base payoff for EV adoption\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta_I\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Payoff enhancement factor for EV adoption\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Payoff for ICE defection\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mg_I\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Infrastructure growth rate\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mI0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Initial infrastructure level\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Random seed for reproducibility\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Whether to collect agent and model-level data\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy_choice_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimitate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Strategy selection function\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Temperature parameter for softmax choice (only used with \"logit\")\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\uva_csp\\model_b_decisioon_making\\3_assign\\course_matterial\\ev_core.py:244\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, G, initial_ev, a0, beta_I, b, g_I, I0, seed, n_nodes, p, m, collect, strategy_choice_func, tau)\u001b[0m\n\u001b[0;32m    242\u001b[0m \n\u001b[0;32m    243\u001b[0m         # initialize node attribute for agent reference\n\u001b[1;32m--> 244\u001b[0m         for n in self.G.nodes:\n\u001b[0;32m    245\u001b[0m             self.G.nodes[n][\"agent\"] = []\n\u001b[0;32m    246\u001b[0m \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EVStagHuntModel' object has no attribute 'G'"
     ]
    }
   ],
   "source": [
    "# Initialize the model with the pre-existing graph\n",
    "    #  EVAgent(Agent) is in EVStagHuntModel(Model), so only need to call this \n",
    "    \n",
    "model = EVStagHuntModel(\n",
    "    G=bowdoin47_RW,\n",
    "    initial_ev=10,  # Number of initial EV nodes\n",
    "    a0=2.0,        # Base payoff for EV adoption\n",
    "    beta_I=3.0,    # Payoff enhancement factor for EV adoption\n",
    "    b=1.0,         # Payoff for ICE defection\n",
    "    g_I=0.1,       # Infrastructure growth rate\n",
    "    I0=0.05,       # Initial infrastructure level\n",
    "    seed=42,       # Random seed for reproducibility\n",
    "    collect=True,  # Whether to collect agent and model-level data\n",
    "    strategy_choice_func=\"imitate\",  # Strategy selection function\n",
    "    tau=1.0        # Temperature parameter for softmax choice (only used with \"logit\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41711385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Run the model for a specified number of steps\n",
    "num_steps = 100\n",
    "for i in range(num_steps):\n",
    "    model.step()\n",
    "\n",
    "# Step 4: Collect and analyze data\n",
    "data = model.datacollector.get_model_vars_dataframe()\n",
    "print(data)\n",
    "\n",
    "# Optionally, you can also collect agent-level data\n",
    "agent_data = model.datacollector.get_agent_vars_dataframe()\n",
    "print(agent_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed474d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for the trial\n",
    "X0_frac = 0.1  # Initial fraction of EV adopters\n",
    "ratio = 2.0    # Payoff ratio\n",
    "I0 = 0.05      # Initial infrastructure level\n",
    "beta_I = 2.0   # Payoff enhancement factor\n",
    "b = 1.0        # Payoff for ICE defection\n",
    "g_I = 0.05     # Infrastructure growth rate\n",
    "T = 200        # Number of time steps\n",
    "seed = 10      # Random seed for reproducibility\n",
    "tol = 1e-3     # Tolerance for stability\n",
    "patience = 30  # Patience for early stopping\n",
    "collect = False # Whether to collect data\n",
    "strategy_choice_func = \"imitate\" # Strategy selection function\n",
    "tau = 1.0      # Temperature parameter for logit choice\n",
    "\n",
    "\n",
    "# Run the trial\n",
    "final_adoption_fraction = run_network_trial(\n",
    "    G=bowdoin47_RW,\n",
    "    X0_frac=X0_frac,\n",
    "    ratio=ratio,\n",
    "    I0=I0,\n",
    "    beta_I=beta_I,\n",
    "    b=b,\n",
    "    g_I=g_I,\n",
    "    T=T,\n",
    "    seed=seed,\n",
    "    tol=tol,\n",
    "    patience=patience,\n",
    "    collect=collect,\n",
    "    strategy_choice_func=strategy_choice_func,\n",
    "    tau=tau,\n",
    ")\n",
    "\n",
    "print(f\"Final adoption fraction: {final_adoption_fraction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "826ccd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def run_network_trial(\n",
      "    G,\n",
      "    X0_frac: float,\n",
      "    ratio: float,\n",
      "    *,\n",
      "    I0: float = 0.05,\n",
      "    beta_I: float = 2.0,\n",
      "    b: float = 1.0,\n",
      "    g_I: float = 0.05,\n",
      "    T: int = 200,\n",
      "    #network_type: str = \"random\",\n",
      "    #n_nodes: int = 120,\n",
      "    #p: float = 0.05,\n",
      "    #m: int = 2,\n",
      "    seed: int = 10, \n",
      "    tol: float = 1e-3,\n",
      "    patience: int = 30,\n",
      "    collect: bool = False,\n",
      "    strategy_choice_func: str = \"imitate\",\n",
      "    tau: float = 1.0,\n",
      ") -> float:\n",
      "        \n",
      "    \"\"\"Run a single realisation and return final adoption fraction.\n",
      "\n",
      "    Preserves the intended initial payoff ratio via a0 = ratio*b - beta_I*I0.\n",
      "    Includes basic stability-based early stopping.\n",
      "    \"\"\"\n",
      "    initial_ev = int(round(X0_frac * G.number_of_nodes()))\n",
      "    a0 = ratio * b - beta_I * I0\n",
      "\n",
      "    model = EVStagHuntModel(\n",
      "        self=self,\n",
      "        G=G,\n",
      "        initial_ev=initial_ev,\n",
      "        a0=a0,\n",
      "        beta_I=beta_I,\n",
      "        b=b,\n",
      "        g_I=g_I,\n",
      "        I0=I0,\n",
      "        seed=seed,\n",
      "        #network_type=network_type,\n",
      "        #n_nodes=n_nodes,\n",
      "        #p=p,\n",
      "        #m=m,\n",
      "        collect=collect,\n",
      "        strategy_choice_func=strategy_choice_func,\n",
      "        tau=tau,\n",
      "    )\n",
      "\n",
      "    stable_steps = 0\n",
      "    prev_X = None\n",
      "    prev_I = None\n",
      "    for _ in range(T):\n",
      "        model.step()\n",
      "        X = model.get_adoption_fraction()\n",
      "        I = model.infrastructure\n",
      "        if prev_X is not None and prev_I is not None:\n",
      "            if abs(X - prev_X) < tol and abs(I - prev_I) < tol:\n",
      "                stable_steps += 1\n",
      "            else:\n",
      "                stable_steps = 0\n",
      "        prev_X, prev_I = X, I\n",
      "        if X in (0.0, 1.0) and stable_steps >= 10:\n",
      "            break\n",
      "        if stable_steps >= patience:\n",
      "            break\n",
      "\n",
      "    return model.get_adoption_fraction()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(run_network_trial))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d079513d",
   "metadata": {},
   "source": [
    "## 1. Baseline System Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trough plots \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72ca2c4",
   "metadata": {},
   "source": [
    "## 2. Network Structure Analysis\n",
    "\n",
    "Seems that the follwoing will be done with plots \n",
    "- speedofadoption,\n",
    "- probability of reaching the high-adoption equilibrium,\n",
    "- cluster formation,\n",
    "- network-specific sensitivity to tipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f8b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mainly could use ev_plotting for this, but there is also some matterial in ev_experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ae5d6",
   "metadata": {},
   "source": [
    "## 3. Policy Intervention Designand Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45cc13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this one the ev_experiments mainly perevelent: \n",
    "    # policy_subsidy_factory = Create a policy that temporarily boosts coordination payoffs\n",
    "    # policy_infrastructure_boost_factory = Create a policy that injects infrastructure at a specific step\n",
    "    \n",
    "# However, these are only two interventions, and we wnat to test possibly more or others \n",
    "    # Can still be used for insparation / a basis to start from \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
